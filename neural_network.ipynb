{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nakajinbee/zero-tuku-deep-learning-2/blob/main/neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "cm-ClMZVt0cd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# def sigmoid(x):\n",
    "#     return 1 /(1 + np.exp(-x))\n",
    "\n",
    "# x = np.random.randn(10, 2)\n",
    "# w1 = np.random.randn(2, 4)\n",
    "# b1 = np.random.randn(4)\n",
    "# w2 = np.random.randn(4, 3)\n",
    "# b2 = np.random.randn(3)\n",
    "\n",
    "# h = np.dot(x,w1) + b1\n",
    "# print(\"hの値：\")\n",
    "# print(h)\n",
    "# a = sigmoid(h)\n",
    "# print(\"aの値：\")\n",
    "# print(a)\n",
    "# s = np.dot(a, w2) + b2\n",
    "# print(\"sの値\")\n",
    "# print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "osDinUWrcdG5"
   },
   "outputs": [],
   "source": [
    "# Sigmoidレイア \n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = 1/(1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 * self.out) * self.out\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "7rr_QUCdd2w2"
   },
   "outputs": [],
   "source": [
    "# 全結合層レイアであるAffineレイア\n",
    "class Affine:\n",
    "    def __init__(self, w, b):\n",
    "        self.params = [w, b]\n",
    "        self.grads  = [np.zeros_like(w), np.zeros_like(b)]\n",
    "        self.x = None\n",
    "\n",
    " \n",
    "    def forward(self,x):\n",
    "        w, b = self.params\n",
    "        out = np.dot(x, w) + b\n",
    "        self.x = x\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        w, b = self.params\n",
    "        dx = np.dot(dout, w.T)\n",
    "        dw = np.dot(self.x.T, dout) \n",
    "        db = np.sum(dout, axis=0)\n",
    "\n",
    "        self.grads[0][...] = dw\n",
    "        self.grads[1][...] = db\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "p4uIyaHEeLFU"
   },
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        I, H, O = input_size, hidden_size, output_size\n",
    "\n",
    "        # 重みとバイアスの初期化\n",
    "        w1 = 0.01 * np.random.randn(I,H)\n",
    "        b1 = np.zeros(H)\n",
    "        w2 = 0.01 * np.random.randn(H,O)\n",
    "        b2 = np.zeros(0)\n",
    "\n",
    "        self.layers = [\n",
    "                       Affine(w1, b1),\n",
    "                       Sigmoid(),\n",
    "                       Affine(w2, b2)\n",
    "        ]\n",
    "\n",
    "        self.loss_layer = SoftmaxWithLoss()\n",
    "\n",
    "\n",
    "        # 全ての重みをリストにまとめる\n",
    "        self.params, self.grads = [],[]\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        score = self.predict(x)\n",
    "        loss = self.loss_layer.forward(score, t)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "RJWOU6wFgCKe"
   },
   "outputs": [],
   "source": [
    "# x = np.random.randn(10, 2)\n",
    "# model = TwoLayerNet(2, 4, 3)\n",
    "# s = model.predict(x)\n",
    "\n",
    "# print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "R790-3rlgiRD"
   },
   "outputs": [],
   "source": [
    "class MatMul:\n",
    "    def __init__(w):\n",
    "        self.params = [w]\n",
    "        self.grads = [np.zeros_like(w)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        w, = self.params\n",
    "        out = np.dot(x,w)\n",
    "        self.x = x\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        w, = self.params\n",
    "        dx = np.dot(dout, w.T)\n",
    "        dw = np.dot(self.x.T, dout)\n",
    "        self.grads[0][...] = dw\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "RE5tWmQ8yw2u"
   },
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "\n",
    "    def softmax(x):\n",
    "        if x.ndim == 2:\n",
    "            x = x - x.max(axis=1, keepdims=True)\n",
    "            x = np.exp(x)\n",
    "            x /= x.sum(axis=1, keepdims=True)\n",
    "        elif x.ndim == 1:\n",
    "            x = x - np.max(x)\n",
    "            x = np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.out = softmax(x)\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = self.out * dout\n",
    "        sumdx = np.sum(dx, axis=1, keepdims=True)\n",
    "        dx -= self.out * sumdx\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1q94gufd6i2Y"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMAduXyo6kKw"
   },
   "source": [
    "誤差逆伝播法によって勾配を求めた\n",
    "⇨勾配を用いてニューラルネットワークのパラメータを更新する\n",
    "\n",
    "step1 ミニバッチ：訓練データの中からランダムに複数のデータを選び出す\n",
    "\n",
    "step2 勾配の算出：誤差逆伝播法により、各重みパラメータに関する損失関数の勾配をもとめる\n",
    "\n",
    "step3 パラメータの更新：勾配を使って重みパラメータを更新する\n",
    "\n",
    "step4 繰り返す：１２３を必要な回数だけ繰り返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "k3rJj20R7UKI"
   },
   "outputs": [],
   "source": [
    "# SDG : Stochastic Gradient Decent (確率的勾配降下法)\n",
    "# lr : learning rate 学習係数\n",
    "\n",
    "class SGD:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "  \n",
    "    def update(self, params, grads):\n",
    "        for i in range(len(params)):\n",
    "            params[i] -= self.lr * grads[i]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_data(seed=1984):\n",
    "    np.random.seed(seed)\n",
    "    N = 100  # クラスごとのサンプル数\n",
    "    DIM = 2  # データの要素数\n",
    "    CLS_NUM = 3  # クラス数\n",
    "\n",
    "    x = np.zeros((N*CLS_NUM, DIM))\n",
    "    t = np.zeros((N*CLS_NUM, CLS_NUM), dtype=np.int64)\n",
    "\n",
    "    for j in range(CLS_NUM):\n",
    "        for i in range(N):#N*j, N*(j+1)):\n",
    "            rate = i / N\n",
    "            radius = 1.0*rate\n",
    "            theta = j*4.0 + 4.0*rate + np.random.randn()*0.2\n",
    "\n",
    "            ix = N*j + i\n",
    "            x[ix] = np.array([radius*np.sin(theta),\n",
    "                              radius*np.cos(theta)]).flatten()\n",
    "            t[ix, j] = 1\n",
    "\n",
    "    return x, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.y = None  # softmaxの出力\n",
    "        self.t = None  # 教師ラベル\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "\n",
    "        # 教師ラベルがone-hotベクトルの場合、正解のインデックスに変換\n",
    "        if self.t.size == self.y.size:\n",
    "            self.t = self.t.argmax(axis=1)\n",
    "\n",
    "        loss = cross_entropy_error(self.y, self.t)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "\n",
    "        dx = self.y.copy()\n",
    "        dx[np.arange(batch_size), self.t] -= 1\n",
    "        dx *= dout\n",
    "        dx = dx / batch_size\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (300, 2)\n",
      "t (300, 3)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x, t = load_data()\n",
    "print('x', x.shape)\n",
    "print('t', t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習用のソースコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ハイパーパラメータの設定\n",
    "max_epoch = 300\n",
    "batch_size = 30\n",
    "hidden_size = 10\n",
    "learning_rate = 1.0\n",
    "\n",
    "x, t = load_data()\n",
    "model = TwoLayerNet(input_size=2, hidden_size=hidden_size, output_size=3)\n",
    "optimizer = SGD(lr=learning_rate)\n",
    "\n",
    "# 学習で使用する変数\n",
    "data_size = len(x)\n",
    "max_iters = data_size // batch_size\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    # データのシャッフル\n",
    "    idx = np.random.permutation(data_size)\n",
    "    x = x[idx]\n",
    "    t = t[idx]\n",
    "\n",
    "    for iters in range(max_iters):\n",
    "        batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
    "        batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
    "        \n",
    "        # 勾配を求め、パラメータを更新\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "        # 定期的に学習経過を出力\n",
    "        if (iters+1) % 10 == 0:\n",
    "            avg_loss = total_loss / loss_count\n",
    "            print('| epoch %d |  iter %d / %d | loss %.2f'\n",
    "                  % (epoch + 1, iters + 1, max_iters, avg_loss))\n",
    "            loss_list.append(avg_loss)\n",
    "            total_loss, loss_count = 0, 0\n",
    "            \n",
    "            \n",
    "            \n",
    "# 学習結果のプロット\n",
    "plt.plot(np.arange(len(loss_list)), loss_list, label='train')\n",
    "plt.xlabel('iterations (x10)')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "\n",
    "# 境界領域のプロット\n",
    "h = 0.001\n",
    "x_min, x_max = x[:, 0].min() - .1, x[:, 0].max() + .1\n",
    "y_min, y_max = x[:, 1].min() - .1, x[:, 1].max() + .1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "X = np.c_[xx.ravel(), yy.ravel()]\n",
    "score = model.predict(X)\n",
    "predict_cls = np.argmax(score, axis=1)\n",
    "Z = predict_cls.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z)\n",
    "plt.axis('off')\n",
    "\n",
    "# データ点のプロット\n",
    "x, t = spiral.load_data()\n",
    "N = 100\n",
    "CLS_NUM = 3\n",
    "markers = ['o', 'x', '^']\n",
    "for i in range(CLS_NUM):\n",
    "    plt.scatter(x[i*N:(i+1)*N, 0], x[i*N:(i+1)*N, 1], s=40, marker=markers[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP6PCJFK2w91R1rjB5/vsY+",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "neural_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
